# -*- coding: utf-8 -*-
"""M22RM007.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mx1KRkDUUuSXzJirM7Se1HXeICPKWP1S

# Soham Padhye (M22RM007)
## Architecture-1 UNet with skip connections
"""

import os
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image

class CustomDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.image_dir = os.path.join(root_dir, "images")
        self.mask_dir = os.path.join(root_dir, "masks")
        self.image_filenames = os.listdir(self.image_dir)
        self.mask_filenames = os.listdir(self.mask_dir)

    def __len__(self):
        return len(self.image_filenames)

    def __getitem__(self, idx):
        img_name = os.path.join(self.image_dir, self.image_filenames[idx])
        mask_name = os.path.join(self.mask_dir, self.mask_filenames[idx])

        image = Image.open(img_name).convert('RGB')
        mask = Image.open(mask_name).convert('L')

        if self.transform:
            image = self.transform(image)
            mask = self.transform(mask)

        return image, mask

# Define transformations
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
])

# Define paths to your dataset
train_dataset = CustomDataset(root_dir="dataset/train", transform=transform)
test_dataset = CustomDataset(root_dir="dataset/test", transform=transform)

# Split train dataset into train and validation
train_size = int(0.8 * len(train_dataset))
val_size = len(train_dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])

# Create dataloaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

import matplotlib.pyplot as plt
import numpy as np

def show_images_masks(loader, num_images=5):
    fig, axes = plt.subplots(num_images, 2, figsize=(10, 10))

    for i, (image, mask) in enumerate(loader):
        if i >= num_images:
            break

        image = image[0]  # Remove batch dimension
        mask = mask[0]    # Remove batch dimension

        # Convert tensors to numpy arrays
        image = image.permute(1, 2, 0).numpy()
        mask = mask.numpy().squeeze()

        # Plot image and mask
        axes[i, 0].imshow(image)
        axes[i, 0].axis('off')
        axes[i, 0].set_title('Image')

        axes[i, 1].imshow(mask, cmap='gray')
        axes[i, 1].axis('off')
        axes[i, 1].set_title('Mask')

    plt.tight_layout()
    plt.show()

# Show some images and masks from train loader
print("Images and Masks from Train Loader:")
show_images_masks(train_loader)

# Show some images and masks from test loader
print("Images and Masks from Test Loader:")
show_images_masks(test_loader)

import torch
import torch.nn as nn
import torchvision.models as models

class DecoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DecoderBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1)
        self.upconv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=2, stride=2)
        self.relu = nn.ReLU()

    def forward(self, x, skip):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.relu(self.conv3(x))
        x = self.upconv(x)
        x = self.upconv(x)
        # print(f"Size at Decoder output is {x.shape}")
        # print(f"Size of skip connection {skip.shape}")
        x = torch.cat([x, skip], dim=1)
        return x

class UNetMobileNet(nn.Module):
    def __init__(self, num_classes):
        super(UNetMobileNet, self).__init__()
        # Load pre-trained MobileNet
        self.encoder = models.mobilenet_v2(pretrained=True).features

        # Define decoder blocks
        self.decoder1 = DecoderBlock(1280, 320)
        self.decoder2 = DecoderBlock(416, 32)
        self.decoder3 = DecoderBlock(32 + 32, 24)
        self.decoder4 = DecoderBlock(24 + 24, 16)

        # Final convolution for segmentation output
        self.final_conv = nn.Conv2d(32, num_classes, kernel_size=1)

    def forward(self, x):
        # Encoder
        features = []
        for name, layer in self.encoder._modules.items():
            x = layer(x)
            # print(f"Layer {name} size: {x.size()}")  # Print feature map size
            if name in ['1', '2', '6', '13']:
                features.append(x)

        # Decoder
        x = self.decoder1(x, features[-1])
        x = self.decoder2(x, features[-2])
        x = self.decoder3(x, features[-3])
        x = self.decoder4(x, features[-4])

        # Final convolution
        x = self.final_conv(x)
        return x

# Example usage:
num_classes = 1  # Assuming binary segmentation
model = UNetMobileNet(num_classes)

"""## Model training"""

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import torch.nn.functional as F
import matplotlib.pyplot as plt

# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the model
num_classes = 1  # Assuming binary segmentation
model = UNetMobileNet(num_classes).to(device)

# Define loss function and optimizer
criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy loss
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Define number of epochs
num_epochs = 30

# Lists to store training and validation losses
train_losses = []
val_losses = []
iou_values = []
dice_values = []

def compute_iou(pred_mask, true_mask):
    intersection = torch.logical_and(pred_mask, true_mask).sum()
    union = torch.logical_or(pred_mask, true_mask).sum()
    iou = intersection / union
    return iou

def compute_dice(pred_mask, true_mask):
    intersection = torch.logical_and(pred_mask, true_mask).sum()
    dice = (2. * intersection) / (pred_mask.sum() + true_mask.sum())
    return dice

# Directory to save model checkpoints
checkpoint_dir = 'checkpoints'
os.makedirs(checkpoint_dir, exist_ok=True)

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, masks in tqdm(train_loader):
        images, masks = images.to(device), masks.to(device)

        # Assuming `mask` is your original mask tensor with shape (32, 1, H_original, W_original)
        resized_mask = F.interpolate(masks, size=(64, 64), mode='bilinear', align_corners=False)
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, resized_mask)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)

    # Calculate training loss
    epoch_loss = running_loss / len(train_loader.dataset)
    train_losses.append(epoch_loss)

    # Validation loop
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for images_val, masks_val in tqdm(val_loader):
            images_val, masks_val = images_val.to(device), masks_val.to(device)
            resized_mask_val = F.interpolate(masks_val, size=(64, 64), mode='bilinear', align_corners=False)
            outputs_val = model(images_val)

            # Apply threshold to the predicted masks
            thresholded_masks = torch.sigmoid(outputs_val) > 0.5

            # Convert masks to boolean tensors
            true_masks = resized_mask_val.bool()
            # print(true_masks.shape)
            pred_masks = thresholded_masks.bool()
            # print(pred_masks.shape)

            # Calculate IoU and Dice for each mask in the batch
            for pred_mask, true_mask in zip(pred_masks, true_masks):
                iou = compute_iou(pred_mask, true_mask)
                dice = compute_dice(pred_mask, true_mask)
                iou_values.append(iou.item())
                dice_values.append(dice.item())

            loss_val = criterion(outputs_val, resized_mask_val)
            val_loss += loss_val.item() * images_val.size(0)
    epoch_val_loss = val_loss / len(val_loader.dataset)
    val_losses.append(epoch_val_loss)

    print(f"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}")
    # Save model checkpoint
    if (epoch + 1) % 10 == 0:
        checkpoint_path = os.path.join(checkpoint_dir, f'unet_mobilenet_segmentation_new_epoch_{epoch+1}.pth')
        torch.save(model.state_dict(), checkpoint_path)

# Plotting the training and validation losses
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Losses')
plt.legend()
plt.show()

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

# Save the trained model
torch.save(model.state_dict(), 'unet_mobilenet_segmentation_model_1.pth')

"""## Model testing"""

import random
import matplotlib.pyplot as plt
import numpy as np

# Define a function to display 10 random images, ground truth masks, and predicted masks
def display_random_samples(images, true_masks, pred_masks):
    for idx in range(20):
        image = images[idx].cpu().numpy().transpose((1, 2, 0))
        true_mask = true_masks[idx].cpu().numpy().squeeze()
        pred_mask = pred_masks[idx].cpu().numpy().squeeze()

        plt.figure(figsize=(15, 5))

        # Original image
        plt.subplot(1, 3, 1)
        plt.imshow(image)
        plt.title('Original Image')
        plt.axis('off')

        # Ground truth mask
        plt.subplot(1, 3, 2)
        plt.imshow(true_mask, cmap='gray')
        plt.title('Ground Truth Mask')
        plt.axis('off')

        # Predicted mask
        plt.subplot(1, 3, 3)
        plt.imshow(pred_mask, cmap='gray')
        plt.title('Predicted Mask')
        plt.axis('off')

        plt.show()

# Load the trained model state dictionary
model_path = 'unet_mobilenet_segmentation_model_1.pth'
model.load_state_dict(torch.load(model_path))
model.eval()  # Set model to evaluation mode

# Testing loop
with torch.no_grad():
    pred_masks_list = []
    true_masks_list = []
    iou_values = []
    dice_values = []
    images_list = []
    for images_test, masks_test in tqdm(test_loader):
        images_test, masks_test = images_test.to(device), masks_test.to(device)
        resized_mask_test = F.interpolate(masks_test, size=(64, 64), mode='bilinear', align_corners=False)
        outputs_test = model(images_test)

        # Apply threshold to the predicted masks
        thresholded_masks = torch.sigmoid(outputs_test) > 0.5

        # Convert masks to boolean tensors
        true_masks = resized_mask_test.bool()
        # print(true_masks.shape)
        pred_masks = thresholded_masks.bool()
        # print(pred_masks.shape)

        # Calculate IoU and Dice for each mask in the batch
        for pred_mask, true_mask in zip(pred_masks, true_masks):
            iou = compute_iou(pred_mask, true_mask)
            dice = compute_dice(pred_mask, true_mask)
            iou_values.append(iou.item())
            dice_values.append(dice.item())

        # Append to lists for later display
        pred_masks_list.append(thresholded_masks)
        true_masks_list.append(resized_mask_test)
        images_list.append(images_test)

# Concatenate lists along the batch dimension
pred_masks = torch.cat(pred_masks_list)
true_masks = torch.cat(true_masks_list)
images = torch.cat(images_list)

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

# Display 10 random samples
display_random_samples(images, true_masks, pred_masks)

"""## Finetuning architecture-1 UNet with skip connections"""

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import torch.nn.functional as F
import torchvision.models as models


# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the model
num_classes = 1  # Assuming binary segmentation
model = UNetMobileNet(num_classes).to(device)

# Define different learning rates for encoder and decoder
encoder_lr = 0.000001  # Learning rate for fine-tuning the encoder
decoder_lr = 0.001   # Learning rate for training the decoder

# Define optimizer with different learning rates for encoder and decoder
encoder_params = list(model.encoder.parameters())
decoder_params = list(model.decoder1.parameters()) + \
                 list(model.decoder2.parameters()) + \
                 list(model.decoder3.parameters()) + \
                 list(model.decoder4.parameters()) + \
                 list(model.final_conv.parameters())

optimizer = optim.Adam([
    {'params': encoder_params, 'lr': encoder_lr},
    {'params': decoder_params, 'lr': decoder_lr}
])

# Define number of epochs
num_epochs = 30

# Lists to store training and validation losses, IOU, and Dice scores
train_losses = []
val_losses = []
iou_values = []
dice_values = []

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, masks in tqdm(train_loader):
        images, masks = images.to(device), masks.to(device)
        resized_mask = F.interpolate(masks, size=(64, 64), mode='bilinear', align_corners=False)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, resized_mask)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)

    epoch_loss = running_loss / len(train_loader.dataset)
    train_losses.append(epoch_loss)

    # Validation loop
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for images_val, masks_val in tqdm(val_loader):
            images_val, masks_val = images_val.to(device), masks_val.to(device)
            resized_mask_val = F.interpolate(masks_val, size=(64, 64), mode='bilinear', align_corners=False)
            outputs_val = model(images_val)
            loss_val = criterion(outputs_val, resized_mask_val)
            val_loss += loss_val.item() * images_val.size(0)

            # Calculate IoU and Dice for each validation batch
            thresholded_masks = torch.sigmoid(outputs_val) > 0.5
            # Convert masks to boolean tensors
            true_masks = resized_mask_val.bool()
            # print(true_masks.shape)
            pred_masks = thresholded_masks.bool()
            # print(pred_masks.shape)

            # Calculate IoU and Dice for each mask in the batch
            for pred_mask, true_mask in zip(pred_masks, true_masks):
                iou = compute_iou(pred_mask, true_mask)
                dice = compute_dice(pred_mask, true_mask)
                iou_values.append(iou.item())
                dice_values.append(dice.item())

    epoch_val_loss = val_loss / len(val_loader.dataset)
    val_losses.append(epoch_val_loss)

    print(f"Epoch [{epoch+1}/{num_epochs}], "
          f"Training Loss: {epoch_loss:.4f}, "
          f"Validation Loss: {epoch_val_loss:.4f}, "
          f"Mean IOU: {sum(iou_values) / len(iou_values):.4f}, "
          f"Mean Dice Score: {sum(dice_values) / len(dice_values):.4f}")

# Save the trained model
torch.save(model.state_dict(), 'unet_mobilenet_segmentation_model_finetuned_1.pth')

# Plotting the training and validation losses
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Losses')
plt.legend()
plt.show()

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

"""## Results on test dataset"""

# Load the trained model state dictionary
model_path = 'unet_mobilenet_segmentation_model_finetuned_1.pth'
model.load_state_dict(torch.load(model_path))
model.eval()  # Set model to evaluation mode


# Testing loop
with torch.no_grad():
    pred_masks_list = []
    true_masks_list = []
    images_list = []
    iou_values = []
    dice_values = []

    for images_test, masks_test in tqdm(test_loader):
        images_test, masks_test = images_test.to(device), masks_test.to(device)
        resized_mask_test = F.interpolate(masks_test, size=(64, 64), mode='bilinear', align_corners=False)
        outputs_test = model(images_test)

        # Apply threshold to the predicted masks
        thresholded_masks = torch.sigmoid(outputs_test) > 0.5
        # Convert masks to boolean tensors
        true_masks = resized_mask_test.bool()
        # print(true_masks.shape)
        pred_masks = thresholded_masks.bool()
        # print(pred_masks.shape)

        # Calculate IoU and Dice for each mask in the batch
        for pred_mask, true_mask in zip(pred_masks, true_masks):
            iou = compute_iou(pred_mask, true_mask)
            dice = compute_dice(pred_mask, true_mask)
            iou_values.append(iou.item())
            dice_values.append(dice.item())

        # Append to lists for later display
        pred_masks_list.append(thresholded_masks)
        true_masks_list.append(resized_mask_test)
        images_list.append(images_test)

# Concatenate lists along the batch dimension
pred_masks = torch.cat(pred_masks_list)
true_masks = torch.cat(true_masks_list)
images = torch.cat(images_list)

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

# Display 10 random samples
display_random_samples(images, true_masks, pred_masks)

"""# Architecture-2 SegNet with Attention"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import torch.nn.functional as F

class AttentionGate(nn.Module):
    def __init__(self, in_channels):
        super(AttentionGate, self).__init__()
        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)
        self.bn = nn.BatchNorm2d(1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # Apply convolution followed by sigmoid to obtain attention coefficients
        alpha = self.sigmoid(self.bn(self.conv(x)))
        # Multiply input feature maps by attention coefficients element-wise
        return x * alpha

class DecoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DecoderBlock, self).__init__()
        self.upconv = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=2, stride=2)
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x, skip):
        # print(f"Size of x is {x.shape}")
        # print(f"Size of skip is {skip.shape}")
        x = torch.cat([x, skip], dim=1)
        x = self.upconv(x)
        x = self.relu(x)
        x = self.bn1(self.conv1(x))
        x = self.relu(x)
        x = self.bn2(self.conv2(x))
        x = self.relu(x)
        x = self.bn3(self.conv3(x))
        x = self.relu(x)
        return x

class UNetMobileNet(nn.Module):
    def __init__(self, num_classes, freeze_encoder=True):
        super(UNetMobileNet, self).__init__()
        # Load pre-trained MobileNet
        self.encoder = models.mobilenet_v2(pretrained=True).features
        # Freeze or unfreeze encoder parameters
        if freeze_encoder:
            for param in self.encoder.parameters():
                param.requires_grad = False

        # Define attention gates
        self.attention1 = AttentionGate(24)
        self.attention2 = AttentionGate(32)
        self.attention3 = AttentionGate(96)
        self.attention4 = AttentionGate(1280)

        # Define decoder blocks
        self.decoder1 = DecoderBlock(2560, 1200)
        self.decoder2 = DecoderBlock(1296, 640)
        self.decoder3 = DecoderBlock(672, 360)
        self.decoder4 = DecoderBlock(384, 16)

        # Final convolution for segmentation output
        self.final_conv = nn.Conv2d(16, num_classes, kernel_size=1)

    def forward(self, x):
        # Encoder
        features = []
        for name, layer in self.encoder._modules.items():
            # print(f"Layer {name} size: {x.size()}")  # Print feature map size
            x = layer(x)
            if name in ['3', '6', '13', '18']:
            # if name in ['1', '2', '6', '13']:
                features.append(x)

        # Apply attention gates
        features[0] = self.attention1(features[0])
        features[1] = self.attention2(features[1])
        features[2] = self.attention3(features[2])
        features[3] = self.attention4(features[3])

        # Decoder
        x = self.decoder1(x, features[-1])
        x = self.decoder2(x, features[-2])
        x = self.decoder3(x, features[-3])
        x = self.decoder4(x, features[-4])

        # Final convolution
        x = self.final_conv(x)

        # print(f"Final shape is {x.shape}")
        return x

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F

# class IoULoss(nn.Module):
#     def __init__(self):
#         super(IoULoss, self).__init__()
#         self.eps = 1e-6

#     def forward(self, y_pred, y_true):
#         # Flatten the input tensors
#         y_pred = y_pred.view(-1)
#         y_true = y_true.view(-1)
#         # Calculate the confusion matrix
#         intersection = (y_pred * y_true).sum()
#         union = y_pred.sum() + y_true.sum() - intersection

#         # Calculate the IoU and return the complement as the loss
#         iou = intersection / (union + self.eps)
#         return 1 - iou


# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# loss_fn = IoULoss().to(device)
# Example usage:
num_classes = 1  # Assuming binary segmentation
model = UNetMobileNet(num_classes, freeze_encoder=True).to(device)

# Define loss function and optimizer
criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy loss

# momentum = 0.9  # Momentum
# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=momentum)
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Define number of epochs
num_epochs = 30

# Lists to store training and validation losses
train_losses = []
val_losses = []
iou_values = []
dice_values = []

def compute_iou(pred_mask, true_mask):
    intersection = torch.logical_and(pred_mask, true_mask).sum()
    union = torch.logical_or(pred_mask, true_mask).sum()
    iou = intersection / union
    return iou

def compute_dice(pred_mask, true_mask):
    intersection = torch.logical_and(pred_mask, true_mask).sum()
    dice = (2. * intersection) / (pred_mask.sum() + true_mask.sum())
    return dice

# Directory to save model checkpoints
checkpoint_dir = 'checkpoints'
os.makedirs(checkpoint_dir, exist_ok=True)

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, masks in tqdm(train_loader):
        images, masks = images.to(device), masks.to(device)

        # Assuming `mask` is your original mask tensor with shape (32, 1, H_original, W_original)
        resized_mask = F.interpolate(masks, size=(64, 64), mode='bilinear', align_corners=False)
        # Forward pass
        outputs = model(images)
        # outputs = model(images.float())
        # loss = loss_fn(outputs.float(), resized_mask.float())
        loss = criterion(outputs, resized_mask)
        running_loss += loss.item() * images.size(0)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()


    # Calculate training loss
    epoch_loss = running_loss / len(train_loader.dataset)
    train_losses.append(epoch_loss)

    # Validation loop
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for images_val, masks_val in tqdm(val_loader):
            images_val, masks_val = images_val.to(device), masks_val.to(device)
            resized_mask_val = F.interpolate(masks_val, size=(64, 64), mode='bilinear', align_corners=False)
            outputs_val = model(images_val)

            # Apply threshold to the predicted masks
            thresholded_masks = torch.sigmoid(outputs_val) > 0.5

            # Convert masks to boolean tensors
            true_masks = resized_mask_val.bool()
            # print(true_masks.shape)
            pred_masks = thresholded_masks.bool()
            # print(pred_masks.shape)

            # Calculate IoU and Dice for each mask in the batch
            for pred_mask, true_mask in zip(pred_masks, true_masks):
                iou = compute_iou(pred_mask, true_mask)
                dice = compute_dice(pred_mask, true_mask)
                iou_values.append(iou.item())
                dice_values.append(dice.item())

            loss_val = criterion(outputs_val, resized_mask_val)
            val_loss += loss_val.item() * images_val.size(0)
    epoch_val_loss = val_loss / len(val_loader.dataset)
    val_losses.append(epoch_val_loss)

    print(f"Epoch [{epoch+1}/{num_epochs}], "
          f"Training Loss: {epoch_loss:.4f}, "
          f"Validation Loss: {epoch_val_loss:.4f}, "
          f"Mean IOU: {sum(iou_values) / len(iou_values):.4f}, "
          f"Mean Dice Score: {sum(dice_values) / len(dice_values):.4f}")
    # Save model checkpoint
    if (epoch + 1) % 10 == 0:
        checkpoint_path = os.path.join(checkpoint_dir, f'unet_mobilenet_segmentation_new_epoch_{epoch+1}.pth')
        torch.save(model.state_dict(), checkpoint_path)

# Plotting the training and validation losses
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Losses')
plt.legend()
plt.show()

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

# Save the trained model
torch.save(model.state_dict(), 'unet_mobilenet_segmentation_model_2.pth')

"""## Results on test dataset"""

import random
import matplotlib.pyplot as plt
import numpy as np


# Load the trained model state dictionary
model_path = 'unet_mobilenet_segmentation_model_2.pth'
model.load_state_dict(torch.load(model_path))
model.eval()  # Set model to evaluation mode

# Testing loop
with torch.no_grad():
    pred_masks_list = []
    true_masks_list = []
    iou_values = []
    dice_values = []
    images_list = []
    for images_test, masks_test in tqdm(test_loader):
        images_test, masks_test = images_test.to(device), masks_test.to(device)
        resized_mask_test = F.interpolate(masks_test, size=(64, 64), mode='bilinear', align_corners=False)
        outputs_test = model(images_test)

        # Apply threshold to the predicted masks
        thresholded_masks = torch.sigmoid(outputs_test) > 0.5

        # Convert masks to boolean tensors
        true_masks = resized_mask_test.bool()
        # print(true_masks.shape)
        pred_masks = thresholded_masks.bool()
        # print(pred_masks.shape)

        # Calculate IoU and Dice for each mask in the batch
        for pred_mask, true_mask in zip(pred_masks, true_masks):
            iou = compute_iou(pred_mask, true_mask)
            dice = compute_dice(pred_mask, true_mask)
            iou_values.append(iou.item())
            dice_values.append(dice.item())

        # Append to lists for later display
        pred_masks_list.append(thresholded_masks)
        true_masks_list.append(resized_mask_test)
        images_list.append(images_test)

# Concatenate lists along the batch dimension
pred_masks = torch.cat(pred_masks_list)
true_masks = torch.cat(true_masks_list)
images = torch.cat(images_list)

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

# Display 10 random samples
display_random_samples(images, true_masks, pred_masks)

"""## Finetuning architecture-2 SegNet with attention"""

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import torch.nn.functional as F
import torchvision.models as models


# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Example usage:
num_classes = 1  # Assuming binary segmentation
model = UNetMobileNet(num_classes, freeze_encoder=False).to(device)

# Define different learning rates for encoder and decoder
encoder_lr = 0.000001  # Learning rate for fine-tuning the encoder
decoder_lr = 0.0001   # Learning rate for training the decoder

# Define optimizer with different learning rates for encoder and decoder
encoder_params = list(model.encoder.parameters())
decoder_params = list(model.decoder1.parameters()) + \
                 list(model.decoder2.parameters()) + \
                 list(model.decoder3.parameters()) + \
                 list(model.decoder4.parameters()) + \
                 list(model.final_conv.parameters())

optimizer = optim.Adam([
    {'params': encoder_params, 'lr': encoder_lr},
    {'params': decoder_params, 'lr': decoder_lr}
])

# loss_fn = IoULoss().to(device)

# Define number of epochs
num_epochs = 30

# Lists to store training and validation losses, IOU, and Dice scores
train_losses = []
val_losses = []
iou_values = []
dice_values = []

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, masks in tqdm(train_loader):
        images, masks = images.to(device), masks.to(device)
        resized_mask = F.interpolate(masks, size=(64, 64), mode='bilinear', align_corners=False)

        # # Forward pass
        # outputs = model(images)
        # loss = criterion(outputs, resized_mask)
        outputs = model(images)
        # outputs = model(images.float())
        # loss = loss_fn(outputs.float(), resized_mask.float())
        loss = criterion(outputs, resized_mask)
        running_loss += loss.item() * images.size(0)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    epoch_loss = running_loss / len(train_loader.dataset)
    train_losses.append(epoch_loss)

    # Validation loop
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for images_val, masks_val in tqdm(val_loader):
            images_val, masks_val = images_val.to(device), masks_val.to(device)
            resized_mask_val = F.interpolate(masks_val, size=(64, 64), mode='bilinear', align_corners=False)
            outputs_val = model(images_val)
            loss_val = criterion(outputs_val, resized_mask_val)
            val_loss += loss_val.item() * images_val.size(0)

            # Calculate IoU and Dice for each validation batch
            thresholded_masks = torch.sigmoid(outputs_val) > 0.5
            # Convert masks to boolean tensors
            true_masks = resized_mask_val.bool()
            # print(true_masks.shape)
            pred_masks = thresholded_masks.bool()
            # print(pred_masks.shape)

            # Calculate IoU and Dice for each mask in the batch
            for pred_mask, true_mask in zip(pred_masks, true_masks):
                iou = compute_iou(pred_mask, true_mask)
                dice = compute_dice(pred_mask, true_mask)
                iou_values.append(iou.item())
                dice_values.append(dice.item())

    epoch_val_loss = val_loss / len(val_loader.dataset)
    val_losses.append(epoch_val_loss)

    print(f"Epoch [{epoch+1}/{num_epochs}], "
          f"Training Loss: {epoch_loss:.4f}, "
          f"Validation Loss: {epoch_val_loss:.4f}, "
          f"Mean IOU: {sum(iou_values) / len(iou_values):.4f}, "
          f"Mean Dice Score: {sum(dice_values) / len(dice_values):.4f}")

# Save the trained model
torch.save(model.state_dict(), 'unet_mobilenet_segmentation_model_finetuned_2.pth')

# Plotting the training and validation losses
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Losses')
plt.legend()
plt.show()

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

"""## Results on test dataset"""

# Load the trained model state dictionary
model_path = 'unet_mobilenet_segmentation_model_finetuned_2.pth'
model.load_state_dict(torch.load(model_path))
model.eval()  # Set model to evaluation mode


# Testing loop
with torch.no_grad():
    pred_masks_list = []
    true_masks_list = []
    images_list = []
    iou_values = []
    dice_values = []

    for images_test, masks_test in tqdm(test_loader):
        images_test, masks_test = images_test.to(device), masks_test.to(device)
        resized_mask_test = F.interpolate(masks_test, size=(64, 64), mode='bilinear', align_corners=False)
        outputs_test = model(images_test)

        # Apply threshold to the predicted masks
        thresholded_masks = torch.sigmoid(outputs_test) > 0.5
        # Convert masks to boolean tensors
        true_masks = resized_mask_test.bool()
        # print(true_masks.shape)
        pred_masks = thresholded_masks.bool()
        # print(pred_masks.shape)

        # Calculate IoU and Dice for each mask in the batch
        for pred_mask, true_mask in zip(pred_masks, true_masks):
            iou = compute_iou(pred_mask, true_mask)
            dice = compute_dice(pred_mask, true_mask)
            iou_values.append(iou.item())
            dice_values.append(dice.item())

        # Append to lists for later display
        pred_masks_list.append(thresholded_masks)
        true_masks_list.append(resized_mask_test)
        images_list.append(images_test)

# Concatenate lists along the batch dimension
pred_masks = torch.cat(pred_masks_list)
true_masks = torch.cat(true_masks_list)
images = torch.cat(images_list)

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

# Display 10 random samples
display_random_samples(images, true_masks, pred_masks)

"""# Architecture-3 SegNet with attention and Atrous Conv"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import torch.nn.functional as F

class AttentionGate(nn.Module):
    def __init__(self, in_channels):
        super(AttentionGate, self).__init__()
        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)
        self.bn = nn.BatchNorm2d(1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # Apply convolution followed by sigmoid to obtain attention coefficients
        alpha = self.sigmoid(self.bn(self.conv(x)))
        # Multiply input feature maps by attention coefficients element-wise
        return x * alpha

class DecoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DecoderBlock, self).__init__()
        self.upconv = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=2, stride=2)
        self.atrous_conv1 = AtrousConvBlock(in_channels, out_channels, dilation_rate=2)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x, skip):
        x = torch.cat([x, skip], dim=1)
        x = self.upconv(x)
        x = self.relu(x)
        x = self.atrous_conv1(x)
        x = self.bn2(self.conv2(x))
        x = self.relu(x)
        x = self.bn3(self.conv3(x))
        x = self.relu(x)
        return x


class AtrousConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels, dilation_rate):
        super(AtrousConvBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=dilation_rate, dilation=dilation_rate)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.relu(x)
        return x

class UNetMobileNet(nn.Module):
    def __init__(self, num_classes, freeze_encoder=True):
        super(UNetMobileNet, self).__init__()
        # Load pre-trained MobileNet
        self.encoder = models.mobilenet_v2(pretrained=True).features
        # Freeze or unfreeze encoder parameters
        if freeze_encoder:
            for param in self.encoder.parameters():
                param.requires_grad = False

        # Define attention gates
        self.attention1 = AttentionGate(24)
        self.attention2 = AttentionGate(32)
        self.attention3 = AttentionGate(96)
        self.attention4 = AttentionGate(1280)

        # Define atrous convolutions
        self.atrous_conv1 = AtrousConvBlock(1280, 1280, dilation_rate=1)
        self.atrous_conv2 = AtrousConvBlock(1280, 1280, dilation_rate=2)

        # Define decoder blocks
        self.decoder1 = DecoderBlock(2560, 1200)
        self.decoder2 = DecoderBlock(1296, 640)
        self.decoder3 = DecoderBlock(672, 360)
        self.decoder4 = DecoderBlock(384, 16)

        # Final convolution for segmentation output
        self.final_conv = nn.Conv2d(16, num_classes, kernel_size=1)

        # # Batch normalization layers
        # self.bn_atrous1 = nn.BatchNorm2d(1280)
        # self.bn_atrous2 = nn.BatchNorm2d(1280)

    def forward(self, x):
        # Encoder
        features = []
        for name, layer in self.encoder._modules.items():
            x = layer(x)
            if name in ['3', '6', '13', '18']:
                features.append(x)

        # Apply attention gates
        features[0] = self.attention1(features[0])
        features[1] = self.attention2(features[1])
        features[2] = self.attention3(features[2])
        features[3] = self.attention4(features[3])

        # Apply atrous convolutions
        x = self.atrous_conv1(features[-1])
        # x = self.bn_atrous1(x)
        # x = F.relu(x)
        x = self.atrous_conv2(x)
        # x = self.bn_atrous2(x)
        # x = F.relu(x)

        # Decoder
        x = self.decoder1(x, features[-1])
        x = self.decoder2(x, features[-2])
        x = self.decoder3(x, features[-3])
        x = self.decoder4(x, features[-4])

        # Final convolution
        x = self.final_conv(x)

        return x

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F

# class IoULoss(nn.Module):
#     def __init__(self):
#         super(IoULoss, self).__init__()
#         self.eps = 1e-6

#     def forward(self, y_pred, y_true):
#         # Flatten the input tensors
#         y_pred = y_pred.view(-1)
#         y_true = y_true.view(-1)
#         # Calculate the confusion matrix
#         intersection = (y_pred * y_true).sum()
#         union = y_pred.sum() + y_true.sum() - intersection

#         # Calculate the IoU and return the complement as the loss
#         iou = intersection / (union + self.eps)
#         return 1 - iou
# def make_one_hot(labels, classes):
#     one_hot = torch.FloatTensor(labels.size()[0], classes, labels.size()[2], labels.size()[3]).zero_().to(labels.device)
#     target = one_hot.scatter_(1, labels.data, 1)
#     return target

# class DiceLoss(nn.Module):
#     def __init__(self, smooth=1., ignore_index=255):
#         super(DiceLoss, self).__init__()
#         self.ignore_index = ignore_index
#         self.smooth = smooth
#     def forward(self, output, target):
#         if self.ignore_index not in range(target.min(), target.max()):
#             if (target == self.ignore_index).sum() > 0:
#                 target[target == self.ignore_index] = target.min()
#         target = make_one_hot(target.unsqueeze(dim=1), classes=output.size()[1])
#         output = F.softmax(output, dim=1)
#         output_flat = output.contiguous().view(-1)
#         target_flat = target.contiguous().view(-1)
#         intersection = (output_flat * target_flat).sum()
#         loss = 1 - ((2. * intersection + self.smooth) /
#                     (output_flat.sum() + target_flat.sum() + self.smooth))
#         return loss

# class CE_DiceLoss(nn.Module):
#     def __init__(self, smooth=1, reduction='mean', weight=None):
#         super(CE_DiceLoss, self).__init__()
#         self.smooth = smooth
#         self.dice = DiceLoss()
#         self.cross_entropy = nn.CrossEntropyLoss(weight=weight, reduction=reduction)

#     def forward(self, output, target):
#         CE_loss = self.cross_entropy(output, target)
#         dice_loss = self.dice(output, target)
#         return CE_loss + dice_loss
import torch
from torchsummary import summary


# Directory to save model checkpoints
checkpoint_dir = 'checkpoints'
os.makedirs(checkpoint_dir, exist_ok=True)

# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

num_classes = 1  # Assuming binary segmentation
model = UNetMobileNet(num_classes, freeze_encoder=True).to(device)

# Print the model summary
summary(model, input_size=(3, 128, 128))  # Assuming input image size is 128x128 and 3 channels (RGB)

# loss_fn = IoULoss().to(device)

# Define loss function and optimizer
criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy loss
# criterion = CE_DiceLoss().to(device)  # Binary Cross Entropy loss

# momentum = 0.9  # Momentum
# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=momentum)
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Define number of epochs
num_epochs = 100

# Lists to store training and validation losses
train_losses = []
val_losses = []
iou_values = []
dice_values = []

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, masks in tqdm(train_loader):
        images, masks = images.to(device), masks.to(device)

        resized_mask = F.interpolate(masks, size=(64, 64), mode='bilinear', align_corners=False)
        # Forward pass
        outputs = model(images)
        # outputs = model(images.float())
        # loss = loss_fn(outputs.float(), resized_mask.float())
        loss = criterion(outputs, resized_mask)
        running_loss += loss.item() * images.size(0)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()


    # Calculate training loss
    epoch_loss = running_loss / len(train_loader.dataset)
    train_losses.append(epoch_loss)

    # Validation loop
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for images_val, masks_val in tqdm(val_loader):
            images_val, masks_val = images_val.to(device), masks_val.to(device)
            resized_mask_val = F.interpolate(masks_val, size=(64, 64), mode='bilinear', align_corners=False)
            outputs_val = model(images_val)

            # Apply threshold to the predicted masks
            thresholded_masks = torch.sigmoid(outputs_val) > 0.5

            # Convert masks to boolean tensors
            true_masks = resized_mask_val.bool()
            # print(true_masks.shape)
            pred_masks = thresholded_masks.bool()
            # print(pred_masks.shape)

            # Calculate IoU and Dice for each mask in the batch
            for pred_mask, true_mask in zip(pred_masks, true_masks):
                iou = compute_iou(pred_mask, true_mask)
                dice = compute_dice(pred_mask, true_mask)
                iou_values.append(iou.item())
                dice_values.append(dice.item())

            loss_val = criterion(outputs_val, resized_mask_val)
            val_loss += loss_val.item() * images_val.size(0)
    epoch_val_loss = val_loss / len(val_loader.dataset)
    val_losses.append(epoch_val_loss)

    print(f"Epoch [{epoch+1}/{num_epochs}], "
          f"Training Loss: {epoch_loss:.4f}, "
          f"Validation Loss: {epoch_val_loss:.4f}, "
          f"Mean IOU: {sum(iou_values) / len(iou_values):.4f}, "
          f"Mean Dice Score: {sum(dice_values) / len(dice_values):.4f}")
    # Save model checkpoint
    if (epoch + 1) % 10 == 0:
        checkpoint_path = os.path.join(checkpoint_dir, f'unet_mobilenet_segmentation_new_epoch_{epoch+1}.pth')
        torch.save(model.state_dict(), checkpoint_path)

# Plotting the training and validation losses
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Losses')
plt.legend()
plt.show()

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

# Save the trained model
torch.save(model.state_dict(), 'unet_mobilenet_segmentation_model_3.pth')

"""## Results on test dataset"""

# Load the trained model state dictionary
model_path = 'unet_mobilenet_segmentation_model_3.pth'
model.load_state_dict(torch.load(model_path))
model.eval()  # Set model to evaluation mode

# Testing loop
with torch.no_grad():
    pred_masks_list = []
    true_masks_list = []
    iou_values = []
    dice_values = []
    images_list = []
    for images_test, masks_test in tqdm(test_loader):
        images_test, masks_test = images_test.to(device), masks_test.to(device)
        resized_mask_test = F.interpolate(masks_test, size=(64, 64), mode='bilinear', align_corners=False)
        outputs_test = model(images_test)

        # Apply threshold to the predicted masks
        thresholded_masks = torch.sigmoid(outputs_test) > 0.5

        # Convert masks to boolean tensors
        true_masks = resized_mask_test.bool()
        # print(true_masks.shape)
        pred_masks = thresholded_masks.bool()
        # print(pred_masks.shape)

        # Calculate IoU and Dice for each mask in the batch
        for pred_mask, true_mask in zip(pred_masks, true_masks):
            iou = compute_iou(pred_mask, true_mask)
            dice = compute_dice(pred_mask, true_mask)
            iou_values.append(iou.item())
            dice_values.append(dice.item())

        # Append to lists for later display
        pred_masks_list.append(thresholded_masks)
        true_masks_list.append(resized_mask_test)
        images_list.append(images_test)

# Concatenate lists along the batch dimension
pred_masks = torch.cat(pred_masks_list)
true_masks = torch.cat(true_masks_list)
images = torch.cat(images_list)

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

# Display 10 random samples
display_random_samples(images, true_masks, pred_masks)

"""## Finetuning architecture-3 SegNet with attention and Atrous convolution"""

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import torch.nn.functional as F
import torchvision.models as models


# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Example usage:
num_classes = 1  # Assuming binary segmentation
model = UNetMobileNet(num_classes, freeze_encoder=False).to(device)

# Define different learning rates for encoder and decoder
encoder_lr = 0.000001  # Learning rate for fine-tuning the encoder
decoder_lr = 0.0001   # Learning rate for training the decoder

# Define optimizer with different learning rates for encoder and decoder
encoder_params = list(model.encoder.parameters())
decoder_params = list(model.decoder1.parameters()) + \
                 list(model.decoder2.parameters()) + \
                 list(model.decoder3.parameters()) + \
                 list(model.decoder4.parameters()) + \
                 list(model.final_conv.parameters())

optimizer = optim.Adam([
    {'params': encoder_params, 'lr': encoder_lr},
    {'params': decoder_params, 'lr': decoder_lr}
])

# loss_fn = IoULoss().to(device)

# Define number of epochs
num_epochs = 100

# Lists to store training and validation losses, IOU, and Dice scores
train_losses = []
val_losses = []
iou_values = []
dice_values = []

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, masks in tqdm(train_loader):
        images, masks = images.to(device), masks.to(device)
        resized_mask = F.interpolate(masks, size=(64, 64), mode='bilinear', align_corners=False)

        # # Forward pass
        # outputs = model(images)
        # loss = criterion(outputs, resized_mask)
        outputs = model(images)
        # outputs = model(images.float())
        # loss = loss_fn(outputs.float(), resized_mask.float())
        loss = criterion(outputs, resized_mask)
        running_loss += loss.item() * images.size(0)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    epoch_loss = running_loss / len(train_loader.dataset)
    train_losses.append(epoch_loss)

    # Validation loop
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for images_val, masks_val in tqdm(val_loader):
            images_val, masks_val = images_val.to(device), masks_val.to(device)
            resized_mask_val = F.interpolate(masks_val, size=(64, 64), mode='bilinear', align_corners=False)
            outputs_val = model(images_val)
            loss_val = criterion(outputs_val, resized_mask_val)
            val_loss += loss_val.item() * images_val.size(0)

            # Calculate IoU and Dice for each validation batch
            thresholded_masks = torch.sigmoid(outputs_val) > 0.5
            # Convert masks to boolean tensors
            true_masks = resized_mask_val.bool()
            # print(true_masks.shape)
            pred_masks = thresholded_masks.bool()
            # print(pred_masks.shape)

            # Calculate IoU and Dice for each mask in the batch
            for pred_mask, true_mask in zip(pred_masks, true_masks):
                iou = compute_iou(pred_mask, true_mask)
                dice = compute_dice(pred_mask, true_mask)
                iou_values.append(iou.item())
                dice_values.append(dice.item())

    epoch_val_loss = val_loss / len(val_loader.dataset)
    val_losses.append(epoch_val_loss)

    print(f"Epoch [{epoch+1}/{num_epochs}], "
          f"Training Loss: {epoch_loss:.4f}, "
          f"Validation Loss: {epoch_val_loss:.4f}, "
          f"Mean IOU: {sum(iou_values) / len(iou_values):.4f}, "
          f"Mean Dice Score: {sum(dice_values) / len(dice_values):.4f}")

# Save the trained model
torch.save(model.state_dict(), 'unet_mobilenet_segmentation_model_finetuned_3.pth')

# Plotting the training and validation losses
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Losses')
plt.legend()
plt.show()

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

"""## Results on test dataset"""

# Load the trained model state dictionary
model_path = 'unet_mobilenet_segmentation_model_finetuned_3.pth'
model.load_state_dict(torch.load(model_path))
model.eval()  # Set model to evaluation mode


# Testing loop
with torch.no_grad():
    pred_masks_list = []
    true_masks_list = []
    images_list = []
    iou_values = []
    dice_values = []

    for images_test, masks_test in tqdm(test_loader):
        images_test, masks_test = images_test.to(device), masks_test.to(device)
        resized_mask_test = F.interpolate(masks_test, size=(64, 64), mode='bilinear', align_corners=False)
        outputs_test = model(images_test)

        # Apply threshold to the predicted masks
        thresholded_masks = torch.sigmoid(outputs_test) > 0.5
        # Convert masks to boolean tensors
        true_masks = resized_mask_test.bool()
        # print(true_masks.shape)
        pred_masks = thresholded_masks.bool()
        # print(pred_masks.shape)

        # Calculate IoU and Dice for each mask in the batch
        for pred_mask, true_mask in zip(pred_masks, true_masks):
            iou = compute_iou(pred_mask, true_mask)
            dice = compute_dice(pred_mask, true_mask)
            iou_values.append(iou.item())
            dice_values.append(dice.item())

        # Append to lists for later display
        pred_masks_list.append(thresholded_masks)
        true_masks_list.append(resized_mask_test)
        images_list.append(images_test)

# Concatenate lists along the batch dimension
pred_masks = torch.cat(pred_masks_list)
true_masks = torch.cat(true_masks_list)
images = torch.cat(images_list)

# Calculate mean IoU and Dice scores
mean_iou = sum(iou_values) / len(iou_values)
mean_dice = sum(dice_values) / len(dice_values)

print(f"Mean IoU: {mean_iou:.4f}")
print(f"Mean Dice Score: {mean_dice:.4f}")

# Display 10 random samples
display_random_samples(images, true_masks, pred_masks)